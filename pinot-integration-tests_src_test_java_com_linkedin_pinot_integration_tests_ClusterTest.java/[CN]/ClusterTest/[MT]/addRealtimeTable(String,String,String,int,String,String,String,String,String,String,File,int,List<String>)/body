{
  JSONObject metadata=new JSONObject();
  metadata.put("streamType","kafka");
  metadata.put(DataSource.STREAM_PREFIX + "." + Kafka.CONSUMER_TYPE,Kafka.ConsumerType.highLevel.toString());
  metadata.put(DataSource.STREAM_PREFIX + "." + Kafka.TOPIC_NAME,kafkaTopic);
  metadata.put(DataSource.STREAM_PREFIX + "." + Kafka.DECODER_CLASS,AvroFileSchemaKafkaAvroMessageDecoder.class.getName());
  metadata.put(DataSource.STREAM_PREFIX + "." + Kafka.ZK_BROKER_URL,kafkaZkUrl);
  metadata.put(DataSource.STREAM_PREFIX + "." + Kafka.HighLevelConsumer.ZK_CONNECTION_STRING,kafkaZkUrl);
  metadata.put(DataSource.Realtime.REALTIME_SEGMENT_FLUSH_SIZE,Integer.toString(realtimeSegmentFlushSize));
  metadata.put(DataSource.STREAM_PREFIX + "." + Kafka.KAFKA_CONSUMER_PROPS_PREFIX+ "."+ "auto.offset.reset","smallest");
  JSONObject request=ControllerRequestBuilder.buildCreateRealtimeTableJSON(tableName,serverTenant,brokerTenant,timeColumnName,timeColumnType,retentionTimeUnit,Integer.toString(retentionDays),1,"BalanceNumSegmentAssignmentStrategy",metadata,schemaName,invertedIndexColumns);
  sendPostRequest(ControllerRequestURLBuilder.baseUrl(CONTROLLER_BASE_API_URL).forTableCreate(),request.toString());
  AvroFileSchemaKafkaAvroMessageDecoder.avroFile=avroFile;
}
