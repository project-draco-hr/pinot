{
  _pinotTableName=pinotTableName;
  _h2TableName=h2TableName;
  File schemaAvroFile=avroFiles.get(0);
  GenericDatumReader<GenericRecord> datumReader=new GenericDatumReader<>();
  try (DataFileReader<GenericRecord> fileReader=new DataFileReader<>(schemaAvroFile,datumReader)){
    Schema schema=fileReader.getSchema();
    for (    Schema.Field field : schema.getFields()) {
      String fieldName=field.name();
      Schema fieldSchema=field.schema();
      Schema.Type fieldType=fieldSchema.getType();
switch (fieldType) {
case UNION:
        _columnNames.add(fieldName);
      _columnToValueSet.put(fieldName,new HashSet<String>());
    Schema.Type type=fieldSchema.getTypes().get(0).getType();
  if (type == Schema.Type.ARRAY) {
    _multiValueColumnMaxNumElements.put(fieldName,0);
  }
 else {
    _singleValueColumnNames.add(fieldName);
    if (type != Schema.Type.STRING && type != Schema.Type.BOOLEAN) {
      _singleValueNumericalColumnNames.add(fieldName);
    }
  }
break;
case ARRAY:
_columnNames.add(fieldName);
_columnToValueSet.put(fieldName,new HashSet<String>());
_multiValueColumnMaxNumElements.put(fieldName,0);
break;
case INT:
case LONG:
case FLOAT:
case DOUBLE:
_columnNames.add(fieldName);
_columnToValueSet.put(fieldName,new HashSet<String>());
_singleValueColumnNames.add(fieldName);
_singleValueNumericalColumnNames.add(fieldName);
break;
case BOOLEAN:
case STRING:
_columnNames.add(fieldName);
_columnToValueSet.put(fieldName,new HashSet<String>());
_singleValueColumnNames.add(fieldName);
break;
default :
LOGGER.warn("Ignoring field {} of type {}",fieldName,fieldType);
break;
}
}
}
 catch (Exception e) {
throw new RuntimeException(e);
}
for (File avroFile : avroFiles) {
addAvroData(avroFile);
}
prepareToGenerateQueries();
}
