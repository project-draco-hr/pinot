{
  _pqlTableName=pqlTableName;
  _h2TableName=h2TableName;
  File schemaAvroFile=avroFiles.get(0);
  GenericDatumReader<GenericRecord> datumReader=new GenericDatumReader<GenericRecord>();
  DataFileReader<GenericRecord> fileReader=null;
  try {
    fileReader=new DataFileReader<GenericRecord>(schemaAvroFile,datumReader);
    Schema schema=fileReader.getSchema();
    for (    Schema.Field field : schema.getFields()) {
      Schema fieldSchema=field.schema();
      Schema.Type fieldType=fieldSchema.getType();
      String fieldName=field.name();
switch (fieldType) {
case UNION:
        List<Schema> unionTypes=fieldSchema.getTypes();
      _columnNames.add(fieldName);
    _columnToValues.put(fieldName,new TreeSet<String>());
  if (unionTypes.get(0).getType() == Schema.Type.ARRAY) {
    _columnNames.add(fieldName);
    _multivalueColumnCardinality.put(fieldName,0);
  }
 else   if (unionTypes.get(0).getType() != Schema.Type.STRING) {
    _nonMultivalueNumericalColumnNames.add(fieldName);
  }
break;
case ARRAY:
_columnNames.add(fieldName);
_multivalueColumnCardinality.put(fieldName,0);
break;
case INT:
case LONG:
case FLOAT:
case DOUBLE:
_columnNames.add(fieldName);
_columnToValues.put(fieldName,new TreeSet<String>());
_nonMultivalueNumericalColumnNames.add(fieldName);
break;
case RECORD:
LOGGER.warn("Ignoring field {} of type RECORD",fieldName);
break;
default :
LOGGER.warn("Ignoring field {} of type {}",fieldName,fieldType);
break;
}
}
}
 catch (Exception e) {
throw new RuntimeException(e);
}
 finally {
IOUtils.closeQuietly(fileReader);
}
for (File avroFile : avroFiles) {
addAvroData(avroFile);
}
prepareToGenerateQueries();
}
