{
  Options opts=new Options();
  opts.addOption("h","help",false,"Prints a help message");
  opts.addOption("r","randomGroupId",false,"Randomly generate a group ID for kafka");
  CommandLine cli=new GnuParser().parse(opts,args);
  if (cli.hasOption("help") || cli.getArgs().length != 3) {
    new HelpFormatter().printHelp("usage: [opts] config.yml kafka.yml rootDir",opts);
    return;
  }
  StarTreeConfig config=StarTreeConfig.decode(new FileInputStream(cli.getArgs()[0]));
  ObjectMapper objectMapper=new ObjectMapper(new YAMLFactory());
  objectMapper.registerModule(new JodaModule());
  final ThirdEyeKafkaConfig kafkaConfig=objectMapper.readValue(new File(cli.getArgs()[1]),ThirdEyeKafkaConfig.class);
  File rootDir=new File(cli.getArgs()[2]);
  if (cli.hasOption("randomGroupId")) {
    kafkaConfig.setGroupId(StandAloneKafkaConsumer.class.getSimpleName() + "_" + UUID.randomUUID());
  }
  final ExecutorService consumerExecutors=Executors.newSingleThreadExecutor();
  final ScheduledExecutorService taskScheduler=Executors.newSingleThreadScheduledExecutor();
  DataUpdateManager dataUpdateManager=new DataUpdateManager(rootDir,false);
  MetricRegistry metricRegistry=new MetricRegistry();
  StarTreeConfig inMemoryConfig=new StarTreeConfig(config.getCollection(),StarTreeRecordStoreFactoryHashMapImpl.class.getCanonicalName(),new Properties(),config.getAnomalyDetectionFunctionClass(),config.getAnomalyDetectionFunctionConfig(),config.getAnomalyHandlerClass(),config.getAnomalyHandlerConfig(),config.getAnomalyDetectionMode(),config.getDimensions(),config.getMetrics(),config.getTime(),config.getJoinSpec(),config.getRollup(),config.getSplit(),false);
  final StarTree mutableTree=new StarTreeImpl(inMemoryConfig);
  mutableTree.open();
  ConsoleReporter reporter=ConsoleReporter.forRegistry(metricRegistry).convertRatesTo(TimeUnit.SECONDS).convertDurationsTo(TimeUnit.MILLISECONDS).build();
  final ThirdEyeKafkaConsumer kafkaConsumer=new ThirdEyeKafkaConsumer(mutableTree,kafkaConfig,consumerExecutors,taskScheduler,dataUpdateManager,metricRegistry);
  Runtime.getRuntime().addShutdownHook(new Thread(){
    @Override public void run(){
      try {
        kafkaConsumer.stop();
        taskScheduler.shutdown();
        consumerExecutors.shutdown();
      }
 catch (      Exception e) {
        throw new RuntimeException(e);
      }
    }
  }
);
  kafkaConsumer.start();
  reporter.start(10,TimeUnit.SECONDS);
}
