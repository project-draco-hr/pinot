{
  this.schema=schema;
  if (tableConfig.getIndexingConfig().getSortedColumn().isEmpty()) {
    LOGGER.info("RealtimeDataResourceZKMetadata contains no information about sorted column");
    this.sortedColumn=null;
  }
 else {
    String firstSortedColumn=tableConfig.getIndexingConfig().getSortedColumn().get(0);
    if (this.schema.isExisted(firstSortedColumn)) {
      LOGGER.info("Setting sorted column name: {} from RealtimeDataResourceZKMetadata.",firstSortedColumn);
      this.sortedColumn=firstSortedColumn;
    }
 else {
      LOGGER.warn("Sorted column name: {} from RealtimeDataResourceZKMetadata is not existed in schema.",firstSortedColumn);
      this.sortedColumn=null;
    }
  }
  this.segmentMetatdaZk=segmentMetadata;
  this.segmentName=segmentMetadata.getSegmentName();
  this.kafkaStreamProviderConfig=new KafkaHighLevelStreamProviderConfig();
  this.kafkaStreamProviderConfig.init(tableConfig,instanceMetadata,schema);
  segmentEndTimeThreshold=start + kafkaStreamProviderConfig.getTimeThresholdToFlushSegment();
  this.resourceDir=new File(resourceDataDir);
  this.resourceTmpDir=new File(resourceDataDir,"_tmp");
  if (!resourceTmpDir.exists()) {
    resourceTmpDir.mkdirs();
  }
  this.mode=mode;
  this.kafkaStreamProvider=StreamProviderFactory.buildStreamProvider();
  this.kafkaStreamProvider.init(kafkaStreamProviderConfig);
  this.kafkaStreamProvider.start();
  realtimeSegment=new RealtimeSegmentImpl(schema,kafkaStreamProviderConfig.getSizeThresholdToFlushSegment());
  realtimeSegment.setSegmentName(segmentMetadata.getSegmentName());
  realtimeSegment.setSegmentMetadata(segmentMetadata,this.schema);
  notifier=realtimeResourceManager;
  segmentStatusTask=new TimerTask(){
    @Override public void run(){
      computeKeepIndexing();
    }
  }
;
  indexingThread=new Thread(new Runnable(){
    @Override public void run(){
      boolean notFull=true;
      long exceptionSleepMillis=50L;
      do {
        try {
          GenericRow row=kafkaStreamProvider.next();
          if (row != null) {
            notFull=realtimeSegment.index(row);
            exceptionSleepMillis=50L;
          }
        }
 catch (        Exception e) {
          LOGGER.warn("Caught exception while indexing row, sleeping for {} ms",exceptionSleepMillis,e);
          Uninterruptibles.sleepUninterruptibly(exceptionSleepMillis,TimeUnit.MILLISECONDS);
          exceptionSleepMillis=Math.min(60000L,exceptionSleepMillis * 2);
        }
catch (        Error e) {
          LOGGER.error("Caught error in indexing thread",e);
          throw e;
        }
      }
 while (notFull && keepIndexing);
      try {
        LOGGER.info("Indexing threshold reached, proceeding with index conversion");
        segmentStatusTask.cancel();
        LOGGER.info("Trying to persist a realtimeSegment - " + realtimeSegment.getSegmentName());
        LOGGER.info("Indexed " + realtimeSegment.getRawDocumentCount() + " raw events, current number of docs = "+ realtimeSegment.getTotalDocs());
        File tempSegmentFolder=new File(resourceTmpDir,"tmp-" + String.valueOf(System.currentTimeMillis()));
        RealtimeSegmentConverter converter=new RealtimeSegmentConverter(realtimeSegment,tempSegmentFolder.getAbsolutePath(),schema,segmentMetadata.getTableName(),segmentMetadata.getSegmentName(),sortedColumn);
        LOGGER.info("Trying to build segment!");
        converter.build();
        File destDir=new File(resourceDataDir,segmentMetadata.getSegmentName());
        FileUtils.deleteQuietly(destDir);
        FileUtils.moveDirectory(tempSegmentFolder.listFiles()[0],destDir);
        FileUtils.deleteQuietly(tempSegmentFolder);
        long startTime=realtimeSegment.getMinTime();
        long endTime=realtimeSegment.getMaxTime();
        TimeUnit timeUnit=schema.getTimeFieldSpec().getOutgoingGranularitySpec().getTimeType();
        swap();
        RealtimeSegmentZKMetadata metadaToOverrite=new RealtimeSegmentZKMetadata();
        metadaToOverrite.setTableName(segmentMetadata.getTableName());
        metadaToOverrite.setSegmentName(segmentMetadata.getSegmentName());
        metadaToOverrite.setSegmentType(SegmentType.OFFLINE);
        metadaToOverrite.setStatus(Status.DONE);
        metadaToOverrite.setStartTime(startTime);
        metadaToOverrite.setEndTime(endTime);
        metadaToOverrite.setTotalDocs(realtimeSegment.getTotalDocs());
        metadaToOverrite.setTimeUnit(timeUnit);
        notifier.notify(metadaToOverrite);
        kafkaStreamProvider.commit();
        kafkaStreamProvider.shutdown();
      }
 catch (      Exception e) {
        LOGGER.error("Caught exception in the realtime indexing thread",e);
      }
    }
  }
);
  indexingThread.start();
  LOGGER.debug("scheduling keepIndexing timer check");
  TimerService.timer.schedule(segmentStatusTask,ONE_MINUTE_IN_MILLSEC,ONE_MINUTE_IN_MILLSEC);
  LOGGER.debug("finished scheduling keepIndexing timer check");
}
