{
  final long routingStartTime=System.nanoTime();
  RoutingTableLookupRequest rtRequest=new RoutingTableLookupRequest(request.getQuerySource().getResourceName());
  Map<ServerInstance,SegmentIdSet> segmentServices=_routingTable.findServers(rtRequest);
  if (segmentServices == null || segmentServices.isEmpty()) {
    LOGGER.info("Not found ServerInstances to Segments Mapping:");
    return null;
  }
  LOGGER.info("Find ServerInstances to Segments Mapping:");
  for (  ServerInstance serverInstance : segmentServices.keySet()) {
    LOGGER.info(serverInstance + " : " + segmentServices.get(serverInstance));
  }
  final long queryRoutingTime=System.nanoTime() - routingStartTime;
  _brokerMetrics.addPhaseTiming(request,BrokerQueryPhase.QUERY_ROUTING,queryRoutingTime);
  final long scatterGatherStartTime=System.nanoTime();
  ScatterGatherRequestImpl scatterRequest=new ScatterGatherRequestImpl(request,segmentServices,_replicaSelection,ReplicaSelectionGranularity.SEGMENT_ID_SET,request.getBucketHashKey(),0,overriddenSelection,_requestIdGen.incrementAndGet(),_brokerTimeOut);
  CompositeFuture<ServerInstance,ByteBuf> response=_scatterGatherer.scatterGather(scatterRequest);
  final Map<ServerInstance,DataTable> instanceResponseMap=new HashMap<ServerInstance,DataTable>();
{
    Map<ServerInstance,ByteBuf> responses=null;
    try {
      responses=response.get();
    }
 catch (    ExecutionException e) {
      LOGGER.warn("Caught exception while fetching response",e);
      _brokerMetrics.addMeteredValue(request,BrokerMeter.REQUEST_FETCH_EXCEPTIONS,1);
    }
    final long scatterGatherTime=System.nanoTime() - scatterGatherStartTime;
    _brokerMetrics.addPhaseTiming(request,BrokerQueryPhase.SCATTER_GATHER,scatterGatherTime);
    final long deserializationStartTime=System.nanoTime();
    Map<ServerInstance,Throwable> errors=response.getError();
    if (null != responses) {
      for (      Entry<ServerInstance,ByteBuf> e : responses.entrySet()) {
        try {
          ByteBuf b=e.getValue();
          byte[] b2=new byte[b.readableBytes()];
          if (b2 == null || b2.length == 0) {
            continue;
          }
          b.readBytes(b2);
          DataTable r2=new DataTable(b2);
          instanceResponseMap.put(e.getKey(),r2);
        }
 catch (        Exception ex) {
          LOGGER.error("Got exceptions in collect query result for instance " + e.getKey() + ", error: "+ ex.getMessage());
          _brokerMetrics.addMeteredValue(request,BrokerMeter.REQUEST_DESERIALIZATION_EXCEPTIONS,1);
        }
      }
    }
    if (null != errors) {
      for (      Entry<ServerInstance,Throwable> e : errors.entrySet()) {
        DataTable r2=new DataTable();
        r2.getMetadata().put("exception",new RequestProcessingException(e.getValue()).toString());
        instanceResponseMap.put(e.getKey(),r2);
        _brokerMetrics.addMeteredValue(request,BrokerMeter.REQUEST_FETCH_EXCEPTIONS,1);
      }
    }
    final long deserializationTime=System.nanoTime() - deserializationStartTime;
    _brokerMetrics.addPhaseTiming(request,BrokerQueryPhase.DESERIALIZATION,deserializationTime);
  }
  try {
    return _brokerMetrics.timePhase(request,BrokerQueryPhase.REDUCE,new Callable<BrokerResponse>(){
      @Override public BrokerResponse call(){
        BrokerResponse returnValue=_reduceService.reduceOnDataTable(request,instanceResponseMap);
        _brokerMetrics.addMeteredValue(request,BrokerMeter.DOCUMENTS_SCANNED,returnValue.getNumDocsScanned());
        return returnValue;
      }
    }
);
  }
 catch (  Exception e) {
    LOGGER.error("Caught exception while processing return",e);
    Utils.rethrowException(e);
    throw new AssertionError("Should not reach this");
  }
}
