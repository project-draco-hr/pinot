{
  ensureDirectoryExistsAndIsEmpty(_tmpDir);
  ensureDirectoryExistsAndIsEmpty(_segmentDir);
  ensureDirectoryExistsAndIsEmpty(_tarDir);
  startCluster();
  final List<File> avroFiles=unpackAvroData(_tmpDir,SEGMENT_COUNT);
  createTable();
  ExecutorService executor=Executors.newCachedThreadPool();
  setupH2AndInsertAvro(avroFiles,executor);
  buildSegmentsFromAvro(avroFiles,executor,0,_segmentDir,_tarDir,"mytable",false);
  setupQueryGenerator(avroFiles,executor);
  executor.shutdown();
  executor.awaitTermination(10,TimeUnit.MINUTES);
  final CountDownLatch latch=setupSegmentCountCountDownLatch("mytable",SEGMENT_COUNT);
  int i=0;
  for (  String segmentName : _tarDir.list()) {
    System.out.println("Uploading segment " + (i++) + " : "+ segmentName);
    File file=new File(_tarDir,segmentName);
    FileUploadUtils.sendSegmentFile("localhost","8998",segmentName,new FileInputStream(file),file.length());
  }
  latch.await();
  TOTAL_DOCS=115545;
  long timeInTwoMinutes=System.currentTimeMillis() + 2 * 60 * 1000L;
  long numDocs;
  while ((numDocs=getCurrentServingNumDocs()) < TOTAL_DOCS) {
    System.out.println("Current number of documents: " + numDocs);
    if (System.currentTimeMillis() < timeInTwoMinutes) {
      Thread.sleep(1000);
    }
 else {
      Assert.fail("Segments were not completely loaded within two minutes");
    }
  }
}
