{
  Job job=Job.getInstance(getConf());
  job.setJobName(name);
  job.setJarByClass(AggregatePhaseJob.class);
  FileSystem fs=FileSystem.get(getConf());
  Configuration configuration=job.getConfiguration();
  String aggConverterClass=getAndSetConfiguration(configuration,AGG_CONVERTER_CLASS);
  job.setMapperClass(AggregationMapper.class);
  if (aggConverterClass.equals(DEFAULT_CONVERTER_CLASS)) {
    Schema schema=new Schema.Parser().parse(fs.open(new Path(getAndCheck(AggregationJobConstants.AGG_INPUT_AVRO_SCHEMA.toString()))));
    LOGGER.info("{}",schema);
    AvroJob.setInputKeySchema(job,schema);
    job.setInputFormatClass(AvroKeyInputFormat.class);
    LOGGER.info("Using default avro inpur format {}",aggConverterClass);
  }
 else {
    LOGGER.info("Setting text input format for {}",aggConverterClass);
    job.setInputFormatClass(TextInputFormat.class);
  }
  job.setMapOutputKeyClass(BytesWritable.class);
  job.setMapOutputValueClass(BytesWritable.class);
  job.setCombinerClass(AggregationReducer.class);
  job.setReducerClass(AggregationReducer.class);
  job.setOutputKeyClass(BytesWritable.class);
  job.setOutputValueClass(BytesWritable.class);
  job.setOutputFormatClass(SequenceFileOutputFormat.class);
  String numReducers=props.getProperty("num.reducers");
  if (numReducers != null) {
    job.setNumReduceTasks(Integer.parseInt(numReducers));
  }
 else {
    job.setNumReduceTasks(10);
  }
  LOGGER.info("Setting number of reducers : " + job.getNumReduceTasks());
  String inputPathDir=getAndSetConfiguration(configuration,AGG_INPUT_PATH);
  getAndSetConfiguration(configuration,AGG_CONFIG_PATH);
  getAndSetConfiguration(configuration,AGG_INPUT_AVRO_SCHEMA);
  getAndSetConfiguration(configuration,AGG_PRESERVE_TIME_COMPACTION);
  Path outputPath=new Path(getAndSetConfiguration(configuration,AGG_OUTPUT_PATH));
  Path aggStatsOutputPath=new Path(outputPath,STATS_FOLDER_SUFFIX);
  Path dimensionStatsPath=new Path(getAndSetConfiguration(configuration,AGG_DIMENSION_STATS_PATH));
  Path metricSumsPath=new Path(getAndSetConfiguration(configuration,AGG_METRIC_SUMS_PATH));
  LOGGER.info("Input path dir: " + inputPathDir);
  FileInputFormat.setInputDirRecursive(job,true);
  for (  String inputPath : inputPathDir.split(",")) {
    Path input=new Path(inputPath);
    FileStatus[] listFiles=fs.listStatus(input);
    boolean isNested=false;
    for (    FileStatus fileStatus : listFiles) {
      if (fileStatus.isDirectory()) {
        isNested=true;
        LOGGER.info("Adding input:" + fileStatus.getPath());
        FileInputFormat.addInputPath(job,fileStatus.getPath());
      }
    }
    if (!isNested) {
      LOGGER.info("Adding input:" + inputPath);
      FileInputFormat.addInputPath(job,input);
    }
  }
  LOGGER.info("Set output paths");
  if (fs.exists(outputPath)) {
    fs.delete(outputPath,true);
  }
  if (fs.exists(aggStatsOutputPath)) {
    fs.delete(aggStatsOutputPath,true);
  }
  if (fs.exists(dimensionStatsPath)) {
    fs.delete(dimensionStatsPath,true);
  }
  if (fs.exists(metricSumsPath)) {
    fs.delete(metricSumsPath,true);
  }
  FileOutputFormat.setOutputPath(job,new Path(getAndCheck(AGG_OUTPUT_PATH.toString())));
  job.waitForCompletion(true);
  Counter counter=job.getCounters().findCounter(AggregationCounter.NUMBER_OF_RECORDS);
  LOGGER.info(counter.getDisplayName() + " : " + counter.getValue());
  if (counter.getValue() == 0) {
    throw new IllegalStateException("No input records in " + inputPathDir);
  }
  counter=job.getCounters().findCounter(AggregationCounter.NUMBER_OF_RECORDS_FLATTENED);
  LOGGER.info(counter.getDisplayName() + " : " + counter.getValue());
  recordMetricSums(configuration,fs,job);
  return job;
}
