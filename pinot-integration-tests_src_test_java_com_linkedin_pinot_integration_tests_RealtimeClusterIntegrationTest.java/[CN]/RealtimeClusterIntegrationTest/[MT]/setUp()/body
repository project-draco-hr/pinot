{
  startZk();
  kafkaStarter=KafkaStarterUtils.startServer(KafkaStarterUtils.DEFAULT_KAFKA_PORT,KafkaStarterUtils.DEFAULT_BROKER_ID,KafkaStarterUtils.DEFAULT_ZK_STR,KafkaStarterUtils.getDefaultKafkaConfiguration());
  KafkaStarterUtils.createTopic(KAFKA_TOPIC,KafkaStarterUtils.DEFAULT_ZK_STR);
  startController();
  startBroker();
  startServer();
  final List<File> avroFiles=unpackAvroData(_tmpDir,SEGMENT_COUNT);
  File schemaFile=getSchemaFile();
  ExecutorService executor=Executors.newCachedThreadPool();
  setupH2AndInsertAvro(avroFiles,executor);
  setupQueryGenerator(avroFiles,executor);
  pushAvroIntoKafka(avroFiles,executor,KAFKA_TOPIC);
  executor.shutdown();
  executor.awaitTermination(10,TimeUnit.MINUTES);
  setUpTable("mytable","DaysSinceEpoch","daysSinceEpoch",KafkaStarterUtils.DEFAULT_ZK_STR,KAFKA_TOPIC,schemaFile,avroFiles.get(0));
  long timeInTwoMinutes=System.currentTimeMillis() + 2 * 60 * 1000L;
  Statement statement=_connection.createStatement(ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY);
  statement.execute("select count(*) from mytable");
  ResultSet rs=statement.getResultSet();
  rs.first();
  int h2RecordCount=rs.getInt(1);
  rs.close();
  waitForRecordCountToStabilizeToExpectedCount(h2RecordCount,timeInTwoMinutes);
}
