{
  startZk();
  kafkaStarter=KafkaStarterUtils.startServer(KafkaStarterUtils.DEFAULT_KAFKA_PORT,KafkaStarterUtils.DEFAULT_BROKER_ID,KafkaStarterUtils.DEFAULT_ZK_STR,KafkaStarterUtils.getDefaultKafkaConfiguration());
  KafkaStarterUtils.createTopic(KAFKA_TOPIC,KafkaStarterUtils.DEFAULT_ZK_STR);
  startController();
  startBroker();
  startServer();
  TarGzCompressionUtils.unTar(new File(TestUtils.getFileFromResourceUrl(RealtimeClusterIntegrationTest.class.getClassLoader().getResource("On_Time_On_Time_Performance_2014_100k_subset_nonulls.tar.gz"))),_tmpDir);
  _tmpDir.mkdirs();
  final List<File> avroFiles=new ArrayList<File>(SEGMENT_COUNT);
  for (int segmentNumber=1; segmentNumber <= SEGMENT_COUNT; ++segmentNumber) {
    avroFiles.add(new File(_tmpDir.getPath() + "/On_Time_On_Time_Performance_2014_" + segmentNumber+ ".avro"));
  }
  File schemaFile=new File(OfflineClusterIntegrationTest.class.getClassLoader().getResource("On_Time_On_Time_Performance_2014_100k_subset_nonulls.schema").getFile());
  setUpTable("mytable","DaysSinceEpoch","daysSinceEpoch",KafkaStarterUtils.DEFAULT_ZK_STR,KAFKA_TOPIC,schemaFile,avroFiles.get(0));
  ExecutorService executor=Executors.newCachedThreadPool();
  Class.forName("org.h2.Driver");
  _connection=DriverManager.getConnection("jdbc:h2:mem:");
  executor.execute(new Runnable(){
    @Override public void run(){
      createH2SchemaAndInsertAvroFiles(avroFiles,_connection);
    }
  }
);
  executor.execute(new Runnable(){
    @Override public void run(){
      _queryGenerator=new QueryGenerator(avroFiles,"'mytable'","mytable");
    }
  }
);
  executor.execute(new Runnable(){
    @Override public void run(){
      pushAvroIntoKafka(avroFiles,KafkaStarterUtils.DEFAULT_KAFKA_BROKER,KAFKA_TOPIC);
    }
  }
);
  executor.shutdown();
  executor.awaitTermination(10,TimeUnit.MINUTES);
  int pinotRecordCount, h2RecordCount;
  long timeInTwoMinutes=System.currentTimeMillis() + 2 * 60 * 1000L;
  Statement statement=_connection.createStatement(ResultSet.TYPE_FORWARD_ONLY,ResultSet.CONCUR_READ_ONLY);
  do {
    Thread.sleep(5000L);
    JSONObject response=postQuery("select count(*) from 'mytable'");
    JSONArray aggregationResultsArray=response.getJSONArray("aggregationResults");
    JSONObject firstAggregationResult=aggregationResultsArray.getJSONObject(0);
    String pinotValue=firstAggregationResult.getString("value");
    pinotRecordCount=Integer.parseInt(pinotValue);
    statement.execute("select count(*) from mytable");
    ResultSet rs=statement.getResultSet();
    rs.first();
    h2RecordCount=rs.getInt(1);
    rs.close();
    LOGGER.info("H2 record count: " + h2RecordCount + "\tPinot record count: "+ pinotRecordCount);
    Assert.assertTrue(System.currentTimeMillis() < timeInTwoMinutes,"Failed to read all records within two minutes");
    TOTAL_DOCS=response.getLong("totalDocs");
  }
 while (h2RecordCount != pinotRecordCount);
}
