{
  filePath=RealtimeFileBasedReaderTest.class.getClassLoader().getResource(AVRO_DATA).getFile();
  fieldTypeMap=new HashMap<>();
  fieldTypeMap.put("column1",FieldType.DIMENSION);
  fieldTypeMap.put("column2",FieldType.DIMENSION);
  fieldTypeMap.put("column3",FieldType.DIMENSION);
  fieldTypeMap.put("column4",FieldType.DIMENSION);
  fieldTypeMap.put("column5",FieldType.DIMENSION);
  fieldTypeMap.put("column6",FieldType.DIMENSION);
  fieldTypeMap.put("column7",FieldType.DIMENSION);
  fieldTypeMap.put("column8",FieldType.DIMENSION);
  fieldTypeMap.put("column9",FieldType.DIMENSION);
  fieldTypeMap.put("column10",FieldType.DIMENSION);
  fieldTypeMap.put("weeksSinceEpochSunday",FieldType.DIMENSION);
  fieldTypeMap.put("daysSinceEpoch",FieldType.DIMENSION);
  fieldTypeMap.put("column13",FieldType.TIME);
  fieldTypeMap.put("count",FieldType.METRIC);
  schema=SegmentTestUtils.extractSchemaFromAvro(new File(filePath),fieldTypeMap,TimeUnit.MINUTES);
  StreamProviderConfig config=new FileBasedStreamProviderConfig(FileFormat.AVRO,filePath,schema);
  StreamProvider provider=new FileBasedStreamProviderImpl();
  final String tableName=RealtimeFileBasedReaderTest.class.getSimpleName() + ".noTable";
  provider.init(config,tableName,new ServerMetrics(new MetricsRegistry()));
  realtimeSegment=new RealtimeSegmentImpl(schema,100000,tableName,segmentName,AVRO_DATA,new ServerMetrics(new MetricsRegistry()));
  GenericRow row=provider.next();
  while (row != null) {
    realtimeSegment.index(row);
    row=provider.next();
  }
  provider.shutdown();
  if (new File("/tmp/realtime").exists()) {
    FileUtils.deleteQuietly(new File("/tmp/realtime"));
  }
  RealtimeSegmentConverter conveter=new RealtimeSegmentConverter(realtimeSegment,"/tmp/realtime",schema,tableName,segmentName,null);
  conveter.build();
  offlineSegment=Loaders.IndexSegment.load(new File("/tmp/realtime").listFiles()[0],ReadMode.mmap);
}
