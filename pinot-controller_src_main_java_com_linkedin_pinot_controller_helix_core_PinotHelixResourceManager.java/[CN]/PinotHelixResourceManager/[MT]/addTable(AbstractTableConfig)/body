{
  TenantConfig tenantConfig=null;
  TableType type=TableType.valueOf(config.getTableType().toUpperCase());
  if (isSingleTenantCluster()) {
    tenantConfig=new TenantConfig();
    tenantConfig.setBroker(ControllerTenantNameBuilder.getBrokerTenantNameForTenant(ControllerTenantNameBuilder.DEFAULT_TENANT_NAME));
switch (type) {
case OFFLINE:
      tenantConfig.setServer(ControllerTenantNameBuilder.getOfflineTenantNameForTenant(ControllerTenantNameBuilder.DEFAULT_TENANT_NAME));
    break;
case REALTIME:
  tenantConfig.setServer(ControllerTenantNameBuilder.getRealtimeTenantNameForTenant(ControllerTenantNameBuilder.DEFAULT_TENANT_NAME));
break;
default :
throw new RuntimeException("UnSupported table type");
}
config.setTenantConfig(tenantConfig);
}
 else {
tenantConfig=config.getTenantConfig();
if (tenantConfig.getBroker() == null || tenantConfig.getServer() == null) {
throw new RuntimeException("missing tenant configs");
}
}
SegmentsValidationAndRetentionConfig segmentsConfig=config.getValidationConfig();
switch (type) {
case OFFLINE:
final String offlineTableName=config.getTableName();
LOGGER.info("building empty ideal state for table : " + offlineTableName);
final IdealState offlineIdealState=PinotTableIdealStateBuilder.buildEmptyIdealStateFor(offlineTableName,Integer.parseInt(segmentsConfig.getReplication()),_helixAdmin,_helixClusterName);
LOGGER.info("adding table via the admin");
_helixAdmin.addResource(_helixClusterName,offlineTableName,offlineIdealState);
LOGGER.info("successfully added the table : " + offlineTableName + " to the cluster");
ZKMetadataProvider.setOfflineTableConfig(_propertyStore,offlineTableName,AbstractTableConfig.toZnRecord(config));
_propertyStore.create(ZKMetadataProvider.constructPropertyStorePathForResource(offlineTableName),new ZNRecord(offlineTableName),AccessOption.PERSISTENT);
break;
case REALTIME:
final String realtimeTableName=config.getTableName();
ZKMetadataProvider.setRealtimeTableConfig(_propertyStore,realtimeTableName,AbstractTableConfig.toZnRecord(config));
KafkaStreamMetadata kafkaStreamMetadata=new KafkaStreamMetadata(config.getIndexingConfig().getStreamConfigs());
IdealState idealState=_helixAdmin.getResourceIdealState(_helixClusterName,realtimeTableName);
if (kafkaStreamMetadata.hasHighLevelKafkaConsumerType()) {
if (kafkaStreamMetadata.hasSimpleKafkaConsumerType()) {
if (idealState == null) {
createHelixEntriesForHighLevelConsumer(config,realtimeTableName);
idealState=_helixAdmin.getResourceIdealState(_helixClusterName,realtimeTableName);
}
}
 else {
if (idealState != null) {
throw new RuntimeException("Table " + realtimeTableName + " already present");
}
createHelixEntriesForHighLevelConsumer(config,realtimeTableName);
}
}
if (kafkaStreamMetadata.hasSimpleKafkaConsumerType()) {
PinotTableIdealStateBuilder.buildLowLevelRealtimeIdealStateFor(realtimeTableName,config,_helixAdmin,_helixClusterName,idealState);
LOGGER.info("Successfully added  helix entries for low-level consumers for {} ",realtimeTableName);
}
LOGGER.info("Successfully added  or updated the table {} ",realtimeTableName);
break;
default :
throw new RuntimeException("UnSupported table type");
}
handleBrokerResource(config);
}
