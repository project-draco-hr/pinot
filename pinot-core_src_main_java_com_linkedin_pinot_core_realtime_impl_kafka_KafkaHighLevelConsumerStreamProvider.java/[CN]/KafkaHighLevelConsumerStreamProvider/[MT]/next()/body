{
  if (kafkaIterator.hasNext()) {
    try {
      GenericRow row=decoder.decode(kafkaIterator.next().message());
      serverMetrics.addMeteredTableValue(tableAndStreamName,ServerMeter.REALTIME_ROWS_CONSUMED,1L);
      serverMetrics.addMeteredGlobalValue(ServerMeter.REALTIME_ROWS_CONSUMED,1L);
      ++currentCount;
      final long now=System.currentTimeMillis();
      if (now - lastLogTime > 60000 || currentCount - lastCount >= 100000) {
        if (lastCount == 0) {
          INSTANCE_LOGGER.info("Consumed {} events from kafka stream {}",currentCount,this.streamProviderConfig.getStreamName());
        }
 else {
          INSTANCE_LOGGER.info("Consumed {} events from kafka stream {} (rate:{}/s)",currentCount - lastCount,this.streamProviderConfig.getStreamName(),(float)(currentCount - lastCount) * 1000 / (now - lastLogTime));
        }
        lastCount=currentCount;
        lastLogTime=now;
      }
      return row;
    }
 catch (    Exception e) {
      INSTANCE_LOGGER.warn("Caught exception while consuming events",e);
      serverMetrics.addMeteredTableValue(tableAndStreamName,ServerMeter.REALTIME_CONSUMPTION_EXCEPTIONS,1L);
      serverMetrics.addMeteredGlobalValue(ServerMeter.REALTIME_CONSUMPTION_EXCEPTIONS,1L);
    }
  }
  return null;
}
