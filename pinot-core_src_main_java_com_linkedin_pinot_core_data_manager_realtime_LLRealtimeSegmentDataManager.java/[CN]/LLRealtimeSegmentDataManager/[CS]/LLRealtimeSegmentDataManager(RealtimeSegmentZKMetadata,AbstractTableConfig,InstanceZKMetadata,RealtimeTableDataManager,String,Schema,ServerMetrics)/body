{
  _segmentZKMetadata=(LLCRealtimeSegmentZKMetadata)segmentZKMetadata;
  _tableConfig=tableConfig;
  _realtimeTableDataManager=realtimeTableDataManager;
  _resourceDataDir=resourceDataDir;
  _schema=schema;
  _serverMetrics=serverMetrics;
  _segmentVersion=SegmentVersion.fromStringOrDefault(tableConfig.getIndexingConfig().getSegmentFormatVersion());
  _instance=_realtimeTableDataManager.getServerInstance();
  _protocolHandler=new ServerSegmentCompletionProtocolHandler(_instance);
  IndexingConfig indexingConfig=_tableConfig.getIndexingConfig();
  KafkaHighLevelStreamProviderConfig kafkaStreamProviderConfig=createStreamProviderConfig();
  kafkaStreamProviderConfig.init(tableConfig,instanceZKMetadata,schema);
  final String bootstrapNodes=indexingConfig.getStreamConfigs().get(CommonConstants.Helix.DataSource.STREAM_PREFIX + "." + CommonConstants.Helix.DataSource.Realtime.Kafka.KAFKA_BROKER_LIST);
  _kafkaTopic=kafkaStreamProviderConfig.getTopicName();
  _segmentNameStr=_segmentZKMetadata.getSegmentName();
  _segmentName=new LLCSegmentName(_segmentNameStr);
  _kafkaPartitionId=_segmentName.getPartitionId();
  _segmentMaxRowCount=kafkaStreamProviderConfig.getSizeThresholdToFlushSegment();
  _tableName=_tableConfig.getTableName();
  segmentLogger=LoggerFactory.getLogger(LLRealtimeSegmentDataManager.class.getName() + "_" + _segmentNameStr);
  if (indexingConfig.getSortedColumn().isEmpty()) {
    segmentLogger.info("RealtimeDataResourceZKMetadata contains no information about sorted column for segment {}",_segmentName);
    _sortedColumn=null;
  }
 else {
    String firstSortedColumn=indexingConfig.getSortedColumn().get(0);
    if (_schema.hasColumn(firstSortedColumn)) {
      segmentLogger.info("Setting sorted column name: {} from RealtimeDataResourceZKMetadata for segment {}",firstSortedColumn,_segmentName);
      _sortedColumn=firstSortedColumn;
    }
 else {
      segmentLogger.warn("Sorted column name: {} from RealtimeDataResourceZKMetadata is not existed in schema for segment {}.",firstSortedColumn,_segmentName);
      _sortedColumn=null;
    }
  }
  _invertedIndexColumns=indexingConfig.getInvertedIndexColumns();
  _tableStreamName=_tableName + "_" + kafkaStreamProviderConfig.getStreamName();
  List<String> invertedIndexColumns=indexingConfig.getInvertedIndexColumns();
  if (_sortedColumn != null && !invertedIndexColumns.contains(_sortedColumn)) {
    invertedIndexColumns.add(_sortedColumn);
  }
  _realtimeSegment=new RealtimeSegmentImpl(schema,_segmentMaxRowCount,tableConfig.getTableName(),segmentZKMetadata.getSegmentName(),_kafkaTopic,_serverMetrics,invertedIndexColumns);
  _realtimeSegment.setSegmentMetadata(segmentZKMetadata,schema);
  _messageDecoder=kafkaStreamProviderConfig.getDecoder();
  _clientId=_kafkaPartitionId + "-" + NetUtil.getHostnameOrAddress();
  _fieldExtractor=(PlainFieldExtractor)FieldExtractorFactory.getPlainFieldExtractor(schema);
  _consumerWrapper=SimpleConsumerWrapper.forPartitionConsumption(new KafkaSimpleConsumerFactoryImpl(),bootstrapNodes,_clientId,_kafkaTopic,_kafkaPartitionId);
  _startOffset=_segmentZKMetadata.getStartOffset();
  _currentOffset=_startOffset;
  _resourceTmpDir=new File(resourceDataDir,"_tmp");
  if (!_resourceTmpDir.exists()) {
    _resourceTmpDir.mkdirs();
  }
  _state=State.INITIAL_CONSUMING;
  long now=now();
  _consumeStartTime=now;
  _consumeEndTime=now + kafkaStreamProviderConfig.getTimeThresholdToFlushSegment();
  start();
}
