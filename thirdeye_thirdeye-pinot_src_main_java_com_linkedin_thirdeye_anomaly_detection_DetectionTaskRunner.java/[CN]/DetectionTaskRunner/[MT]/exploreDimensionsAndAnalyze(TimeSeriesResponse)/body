{
  int anomalyCounter=0;
  List<RawAnomalyResultDTO> results=null;
  Map<DimensionKey,MetricTimeSeries> res=timeSeriesResponseConverter.toMap(finalResponse,collectionDimensions);
  for (  Map.Entry<DimensionKey,MetricTimeSeries> entry : res.entrySet()) {
    if (entry.getValue().getTimeWindowSet().size() < 2) {
      LOG.warn("Insufficient data for {} to run anomaly detection function",entry.getKey());
      continue;
    }
    try {
      DimensionKey dimensionKey=entry.getKey();
      MetricTimeSeries metricTimeSeries=entry.getValue();
      LOG.info("Analyzing anomaly function with dimensionKey: {}, windowStart: {}, windowEnd: {}",dimensionKey,windowStart,windowEnd);
      results=anomalyFunction.analyze(dimensionKey,metricTimeSeries,windowStart,windowEnd,knownAnomalies);
      handleResults(results);
      results.removeAll(knownAnomalies);
      LOG.info("{} has {} anomalies in window {} to {}",entry.getKey(),results.size(),windowStart,windowEnd);
      anomalyCounter+=results.size();
    }
 catch (    Exception e) {
      LOG.error("Could not compute for {}",entry.getKey(),e);
    }
  }
  LOG.info("{} anomalies found in total",anomalyCounter);
}
